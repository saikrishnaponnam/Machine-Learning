
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://saikrishnaponnam.github.io/Machine-Learning/rnn/">
      
      
        <link rel="prev" href="../batch_norm/">
      
      
        <link rel="next" href="../lstm/">
      
      
      <link rel="icon" href="../images/icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>RNN - Machine Learning Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../stylesheets/override.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#rnn" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Machine Learning Notes" class="md-header__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Machine Learning Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              RNN
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/saikrishnaponnam/Machine-Learning.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Machine Learning Notes" class="md-nav__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    Machine Learning Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/saikrishnaponnam/Machine-Learning.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../math/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Fundamentals
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Fundamentals
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Calculus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/linear-algebra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linear Algebra
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Probability
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Initializers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Weight Initializers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../optimizers/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Optimizers
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Optimizers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/adam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/sgd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    SGD
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../regularization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Regularization
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../convolution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Convolution
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../max_pool/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Max Pooling
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../batch_norm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Batch Norm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#working-with-sequences" class="md-nav__link">
    <span class="md-ellipsis">
      Working with sequences
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnns" class="md-nav__link">
    <span class="md-ellipsis">
      RNNs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-rnns" class="md-nav__link">
    <span class="md-ellipsis">
      Training RNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training RNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation-through-time-bptt" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation through time (BPTT)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backpropagation through time (BPTT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-output-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t output weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-input-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t input weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-recurrent-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t recurrent weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-input" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t input
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vanishing-and-exploding-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Vanishing and Exploding Gradients
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Tips
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qa" class="md-nav__link">
    <span class="md-ellipsis">
      Q&amp;A
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../lstm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LSTM
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../models/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/rcnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RCNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/faster_rcnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Faster RCNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/fcos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FCOS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/resnet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Resnet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/vgg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VGG
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Papers
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#working-with-sequences" class="md-nav__link">
    <span class="md-ellipsis">
      Working with sequences
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnns" class="md-nav__link">
    <span class="md-ellipsis">
      RNNs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-rnns" class="md-nav__link">
    <span class="md-ellipsis">
      Training RNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training RNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation-through-time-bptt" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation through time (BPTT)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backpropagation through time (BPTT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-output-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t output weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-input-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t input weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-recurrent-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t recurrent weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-wrt-input" class="md-nav__link">
    <span class="md-ellipsis">
      Gradients w.r.t input
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vanishing-and-exploding-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Vanishing and Exploding Gradients
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Tips
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qa" class="md-nav__link">
    <span class="md-ellipsis">
      Q&amp;A
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="rnn">RNN</h1>
<p>For models like logistic regression and multilayer perceptron (MLP), the input <span class="arithmatex">\(x_i\)</span> is assumed to be a fixed size vector in <span class="arithmatex">\(\mathbb{R}^d\)</span>. 
Such datasets are referred to as tabular datasets.</p>
<p>Image data, on the other hand, consists of a grid of pixels and can be represented as a 2D matrix. 
CNNs are used to process the spatial structure of images. 
However, these data types are still of fixed length.</p>
<p>But how do we handle data that is not of fixed length, such as a sequence of images in a video or a sequence of words in language tasks like image captioning or translation?</p>
<p>Recurrent Neural Networks (RNNs) are designed to process sequential data, where the input length can vary. 
RNNs capture the dynamics of sequences through recurrent connections, allowing them to maintain a memory of previous inputs.</p>
<h2 id="working-with-sequences">Working with sequences</h2>
<p>A sequence consists of an ordered list of feature vectors <span class="arithmatex">\(x_1, \dots, x_T\)</span>, where each <span class="arithmatex">\(x_t \in \mathbb{R}^d\)</span> is indexed by time step <span class="arithmatex">\(t \in \mathbb{Z}^+\)</span>.</p>
<p>While individual inputs are typically assumed to be independently sampled from a distribution <span class="arithmatex">\(P(X)\)</span>, in sequential data, we cannot assume that each time step is independent of the previous ones.</p>
<p>Given a sequential input, the goal may be to predict a single output <span class="arithmatex">\(y\)</span> or sequentially structured output (<span class="arithmatex">\(y_1, \dots, y_T\)</span>).</p>
<h2 id="rnns">RNNs</h2>
<p>An RNN processes sequential input one step at a time, maintaining a hidden state that serves as memory.
Let's denote:</p>
<ul>
<li><span class="arithmatex">\(x_t \in \mathbb{R}^d\)</span>: as the input at time step <span class="arithmatex">\(t\)</span></li>
<li><span class="arithmatex">\(h_t \in \mathbb{R}^d\)</span>: as the hidden state at time step <span class="arithmatex">\(t\)</span></li>
<li><span class="arithmatex">\(y_t \in \mathbb{R}^m\)</span>: as the output at time step <span class="arithmatex">\(t\)</span></li>
<li><span class="arithmatex">\(W_{xh}\)</span>: as the weight matrix for input to hidden state</li>
<li><span class="arithmatex">\(W_{hh}\)</span>: as the weight matrix for hidden state to hidden state</li>
<li><span class="arithmatex">\(W_{hy}\)</span>: as the weight matrix for hidden state to output</li>
<li><span class="arithmatex">\(\phi\)</span>: as the activation function</li>
</ul>
<p>The hidden state <span class="arithmatex">\(h_t\)</span> at time step <span class="arithmatex">\(t\)</span> is computed from the previous hidden state <span class="arithmatex">\(h_{t-1}\)</span> and the current input <span class="arithmatex">\(x_t\)</span>.
This hidden state stores information about the sequence up to that point. 
Unlike traditional deep neural networks, RNNs share the same parameters across all time steps.</p>
<figure>
    <img alt="img.png" src="../images/rnn.png" />
    <figcaption>RNN unrolled</figcaption>
</figure>
<div class="arithmatex">\[h_t = \phi(a_t) = \phi(W_{xh}x_t + W_{hh} h_{t-1} + b_h ) \\
y_t = W_{hy} h_t + b_y\]</div>
<p><img alt="rnn_types.png" src="../images/rnn_types.png" /></p>
<p>Not all RNNs produce output at every time step; some only output at the final time step. 
The key feature of an RNN is its hidden state, which captures information about the sequence.</p>
<h2 id="training-rnns">Training RNNs</h2>
<p>Training RNNs is similar to training other neural networks, but with some additional considerations due to the sequential nature of the data.</p>
<h3 id="loss-function">Loss Function</h3>
<p>The loss function for RNNs can be defined as the sum of the losses at each time step, or as the average loss across all time steps.</p>
<div class="arithmatex">\[L = \frac{1}{T} \sum_{t=1}^{T} L_t(y_t, \hat{y}_t)\]</div>
<p>where <span class="arithmatex">\(L\)</span> is the loss function (e.g., cross-entropy loss), <span class="arithmatex">\(y_t\)</span> is the true output at time step <span class="arithmatex">\(t\)</span>, and <span class="arithmatex">\(\hat{y}_t\)</span> is the predicted output at time step <span class="arithmatex">\(t\)</span>.</p>
<h2 id="backpropagation-through-time-bptt">Backpropagation through time (BPTT)</h2>
<p>When training RNNs, we often use backpropagation through time (BPTT) to compute gradients.
BPTT is an extension of backpropagation that allows us to compute gradients for sequences by unrolling the RNN through time, one step at a time.
The unrolled RNN is treated as a feedforward network, where each time step corresponds to a layer in the network.
But same parameters are shared across all time steps/layers. The gradients are computed for each time step and then accumulated to update the parameters.</p>
<p>Let <span class="arithmatex">\(\delta_y^t = \frac{\partial L_t}{\partial \hat{y}_t}\)</span>, <span class="arithmatex">\(\delta_h^t = \frac{\partial L_t}{\partial h_t}\)</span>, $\delta_a^t = \delta_h^t * \phi'(a_t) $, where <span class="arithmatex">\(\phi'(a_t)\)</span> is the derivative of the activation function element-wise.</p>
<h3 id="gradients-wrt-output-weights">Gradients w.r.t output weights</h3>
<div class="arithmatex">\[\begin{align*}
\frac{\partial L}{\partial  W_{hy}} &amp;= \sum_t \frac{\partial L_t}{\partial W_{hy}} \\
\frac{\partial L_t}{\partial W_{hy}} &amp;= \frac{\partial L_t}{\partial \hat{y}_t} \cdot \frac{\partial \hat{y}_t}{\partial w_{hy}} = \delta_y^t . (h_t)^T \\
\frac{\partial L}{\partial W_{hy}} &amp;= \sum_t {\delta_y^t} \cdot (h_t)^T \\
\end{align*}\]</div>
<h3 id="gradients-wrt-input-weights">Gradients w.r.t input weights</h3>
<p>To update the input-to-hidden weights <span class="arithmatex">\(W_{xh}\)</span>, we compute the gradient of the loss with respect to <span class="arithmatex">\(W_{xh}\)</span> by accumulating contributions from all time steps:</p>
<div class="arithmatex">\[\begin{align*}
\frac{\partial L}{\partial  W_{xh}} &amp;= \sum_t \frac{\partial L}{\partial  a_t} \cdot \frac{\partial a_t}{\partial  W_{xh}} \\
\frac{\partial a_t}{\partial  W_{xh}} &amp;= (x_t)^T\\
\frac{\partial L}{\partial  a_t} &amp;= \frac{\partial L}{\partial h_t} \frac{\partial h_t}{\partial a_t} = \frac{\partial L}{\partial h_t} * \phi'(a_t) \\ 
\frac{\partial L}{\partial  h_t} &amp;= \frac{\partial L_t}{\partial h_t} + \frac{\partial L}{\partial h_{t+1}} \frac{\partial h_{t+1}}{\partial h_t} \\
\frac{\partial L}{\partial  h_t} &amp;= \frac{\partial L_t}{\partial h_t} + \frac{\partial L}{\partial h_{t+1}} * \phi(a_{t+1}) \cdot W_{hh}^T \\
\frac{\partial L}{\partial w_{xh}} &amp;= \sum_t \delta_h^t * \phi'(a_t) \cdot (x_t)^T \\ 
\text{where } \delta_h^t &amp;= \frac{\partial L_t}{\partial h_t} + \delta_h^{t+1} * \phi'(a_{t+1}) \cdot (w_{hh})^T = \frac{\partial L_t}{\partial h_t} + \frac{\partial L}{\partial a_{t+1}} \cdot (w_{hh})^T   \\
\end{align*}\]</div>
<p>We get <span class="arithmatex">\(\frac{\partial L_t}{\partial h_t}\)</span> from the output (<span class="arithmatex">\(y_t\)</span> - Linear layer) or sometimes directly from loss function.</p>
<h3 id="gradients-wrt-recurrent-weights">Gradients w.r.t recurrent weights</h3>
<p>Similar to above</p>
<div class="arithmatex">\[\begin{align*}
\frac{\partial L}{\partial  W_{hh}} &amp;= \sum_t \frac{\partial L}{\partial  a_t} \cdot \frac{\partial a_t}{\partial  W_{hh}} \\
\frac{\partial a_t}{\partial  W_{hh}} &amp;= (h_{t-1})^T\\
\frac{\partial L}{\partial w_{hh}} &amp;= \sum_t \delta_h^t * \phi'(a_t) \cdot (h_{t-1})^T \\
\end{align*}\]</div>
<h3 id="gradients-wrt-input">Gradients w.r.t input</h3>
<div class="arithmatex">\[\begin{align*}
\frac{\partial L}{\partial  x_t} &amp;= \sum_{t} \frac{\partial L}{\partial  a_t} \cdot \frac{\partial a_t}{\partial x_t} \\
\frac{\partial L}{\partial  x_t} &amp;= \sum_{t} \frac{\partial L}{\partial  a_t} \cdot (W_{xh})^T \\
\end{align*}\]</div>
<h3 id="vanishing-and-exploding-gradients">Vanishing and Exploding Gradients</h3>
<p>Although RNNs are theoretically capable of utilizing information from sequences of any length, in practice they are constrained to remembering only a limited number of previous steps. 
This limitation arises because RNNs often experience vanishing or exploding gradients, which makes training on long sequences challenging.
This mainly occurs because <span class="arithmatex">\(\frac{dL}{dh_t}\)</span> depends on <span class="arithmatex">\(\frac{\partial h_t}{\partial h_k}\)</span>, which itself is a chain of derivatives. 
With small values in the weight matrices and repeated matrix multiplications (especially as <span class="arithmatex">\( t-k \)</span> increases), the gradients shrink exponentially, often vanishing after just a few time steps.
As a result, gradient contributions from distant time steps become negligible, and the model fails to learn long-range dependencies.</p>
<h2 id="gradient-clipping">Gradient Clipping</h2>
<p>Gradient clipping is a technique used to mitigate exploding gradients by capping the gradients during backpropagation.</p>
<h2 id="practical-tips">Practical Tips</h2>
<p>When implementing RNNs, consider the following:
- <strong>Batching</strong>: RNNs can be trained on batches of sequences, but care must be taken to handle variable-length sequences. Padding is often used to ensure that all sequences in a batch have the same length.
- <strong>Regularization</strong>: Techniques like dropout can be applied to RNNs, but they need to be adapted for sequential data. Variants like variational dropout or zoneout are often used.</p>
<h2 id="qa">Q&amp;A</h2>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>