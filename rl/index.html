
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://saikrishnaponnam.github.io/Machine-Learning/rl/">
      
      
        <link rel="prev" href="../tokenization/neural_tokenizer/">
      
      
        <link rel="next" href="../models/">
      
      
      <link rel="icon" href="../images/icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Reinforcement Learning - Machine Learning Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../stylesheets/override.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reinforcement-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Machine Learning Notes" class="md-header__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Machine Learning Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Reinforcement Learning
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/saikrishnaponnam/Machine-Learning.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Machine Learning Notes" class="md-nav__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    Machine Learning Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/saikrishnaponnam/Machine-Learning.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ML Notes
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../math/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Fundamentals
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Fundamentals
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Calculus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/linear-algebra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linear Algebra
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Probability
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    NLP Overview
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Initializers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Weight Initializers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../optimizers/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Optimizers
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Optimizers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/adam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/sgd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    SGD
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../regularization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Regularization
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../convolution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Convolution
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../max_pool/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Max Pooling
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../batch_norm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Batch Norm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../lstm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LSTM
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../tokenization/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Tokenization
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_12" id="__nav_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            Tokenization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/hf_tokenizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HF Tokenizer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/bpe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BPE Tokenization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/wordpiece/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    WordPiece [WIP]
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/unigram/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Unigram [WIP]
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/neural_tokenizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neural Tokenizer [WIP]
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-components" class="md-nav__link">
    <span class="md-ellipsis">
      Key Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-process" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications" class="md-nav__link">
    <span class="md-ellipsis">
      Applications
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rl-framework" class="md-nav__link">
    <span class="md-ellipsis">
      RL Framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RL Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agent-environment-interaction" class="md-nav__link">
    <span class="md-ellipsis">
      Agent-Environment Interaction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#markov-decision-process-mdp" class="md-nav__link">
    <span class="md-ellipsis">
      Markov Decision Process (MDP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy" class="md-nav__link">
    <span class="md-ellipsis">
      Policy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reward-signal" class="md-nav__link">
    <span class="md-ellipsis">
      Reward Signal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#return-discounted-and-undiscounted" class="md-nav__link">
    <span class="md-ellipsis">
      Return (Discounted and Undiscounted)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#value-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Value Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bellman-equations" class="md-nav__link">
    <span class="md-ellipsis">
      Bellman Equations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exploration-and-exploitation" class="md-nav__link">
    <span class="md-ellipsis">
      Exploration and Exploitation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Exploration and Exploitation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#greedy-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Greedy Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#epsilon-greedy-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Epsilon-Greedy Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax Exploration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upper-confidence-bound-ucb" class="md-nav__link">
    <span class="md-ellipsis">
      Upper Confidence Bound (UCB)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classical-rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Classical RL Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classical RL Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Programming
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#monte-carlo-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Monte Carlo Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#temporal-difference-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Temporal Difference Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eligibility-traces" class="md-nav__link">
    <span class="md-ellipsis">
      Eligibility Traces
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#function-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Function Approximation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Function Approximation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#value-function-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Value Function Approximation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Approximation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#actor-critic-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Actor-Critic Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Reinforcement Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deep Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deep-q-networks-dqn" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Q-Networks (DQN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-policy-gradient-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Policy Gradient Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-based-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Model-Based RL
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-rl-problem" class="md-nav__link">
    <span class="md-ellipsis">
      The RL Problem
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The RL Problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#markov-decision-process-mdp_1" class="md-nav__link">
    <span class="md-ellipsis">
      Markov Decision Process (MDP)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#types-of-rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Types of RL Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Types of RL Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-value-based-methods" class="md-nav__link">
    <span class="md-ellipsis">
      1. Value-Based Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-policy-based-methods" class="md-nav__link">
    <span class="md-ellipsis">
      2. Policy-Based Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-model-based-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Model-Based Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exploration-vs-exploitation" class="md-nav__link">
    <span class="md-ellipsis">
      Exploration vs. Exploitation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-reinforcement-learning_1" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applications-of-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Applications of RL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-in-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Challenges in RL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      Further Reading
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../models/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14" id="__nav_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/rcnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RCNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/faster_rcnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Faster RCNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/fcos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FCOS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/vgg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VGG
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../papers/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Papers
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_15" id="__nav_15_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            Papers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../papers/cv/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Vision
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_15_1" id="__nav_15_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_1">
            <span class="md-nav__icon md-icon"></span>
            Vision
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/cv/resnet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ResNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/cv/vit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ViT
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../papers/fine-tuning/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Fine Tuning
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_15_2" id="__nav_15_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_2">
            <span class="md-nav__icon md-icon"></span>
            Fine Tuning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/fine-tuning/lora/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LoRA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/fine-tuning/rlhf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RLHF [WIP]
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../papers/nlp/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    NLP
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_15_3" id="__nav_15_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_3">
            <span class="md-nav__icon md-icon"></span>
            NLP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/seq2seq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Seq2Seq
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/additive_attention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Additive Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/dot_product_attention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dot Product Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/transformer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/efficient_transformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Efficient Transformers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/GPT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GPT-1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/bert/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BERT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/t5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    T5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/gpt2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GPT-2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/nlp/llama/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLaMA
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-components" class="md-nav__link">
    <span class="md-ellipsis">
      Key Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-process" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications" class="md-nav__link">
    <span class="md-ellipsis">
      Applications
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rl-framework" class="md-nav__link">
    <span class="md-ellipsis">
      RL Framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RL Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agent-environment-interaction" class="md-nav__link">
    <span class="md-ellipsis">
      Agent-Environment Interaction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#markov-decision-process-mdp" class="md-nav__link">
    <span class="md-ellipsis">
      Markov Decision Process (MDP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy" class="md-nav__link">
    <span class="md-ellipsis">
      Policy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reward-signal" class="md-nav__link">
    <span class="md-ellipsis">
      Reward Signal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#return-discounted-and-undiscounted" class="md-nav__link">
    <span class="md-ellipsis">
      Return (Discounted and Undiscounted)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#value-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Value Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bellman-equations" class="md-nav__link">
    <span class="md-ellipsis">
      Bellman Equations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exploration-and-exploitation" class="md-nav__link">
    <span class="md-ellipsis">
      Exploration and Exploitation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Exploration and Exploitation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#greedy-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Greedy Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#epsilon-greedy-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Epsilon-Greedy Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax Exploration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upper-confidence-bound-ucb" class="md-nav__link">
    <span class="md-ellipsis">
      Upper Confidence Bound (UCB)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classical-rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Classical RL Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classical RL Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Programming
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#monte-carlo-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Monte Carlo Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#temporal-difference-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Temporal Difference Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eligibility-traces" class="md-nav__link">
    <span class="md-ellipsis">
      Eligibility Traces
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#function-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Function Approximation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Function Approximation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#value-function-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Value Function Approximation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Approximation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#actor-critic-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Actor-Critic Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Reinforcement Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deep Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deep-q-networks-dqn" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Q-Networks (DQN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-policy-gradient-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Policy Gradient Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-based-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Model-Based RL
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-rl-problem" class="md-nav__link">
    <span class="md-ellipsis">
      The RL Problem
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The RL Problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#markov-decision-process-mdp_1" class="md-nav__link">
    <span class="md-ellipsis">
      Markov Decision Process (MDP)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#types-of-rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Types of RL Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Types of RL Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-value-based-methods" class="md-nav__link">
    <span class="md-ellipsis">
      1. Value-Based Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-policy-based-methods" class="md-nav__link">
    <span class="md-ellipsis">
      2. Policy-Based Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-model-based-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Model-Based Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exploration-vs-exploitation" class="md-nav__link">
    <span class="md-ellipsis">
      Exploration vs. Exploitation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-reinforcement-learning_1" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Reinforcement Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applications-of-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Applications of RL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-in-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Challenges in RL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      Further Reading
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="reinforcement-learning">Reinforcement Learning</h1>
<h2 id="introduction">Introduction</h2>
<p>Reinforcement Learning (RL) is a branch of machine learning where an agent learns to make decisions by interacting with an environment. Unlike supervised learning, where the model learns from labeled data, RL is based on the idea of learning from experience through trial and error, receiving feedback in the form of rewards or penalties.</p>
<h3 id="key-components">Key Components</h3>
<ul>
<li><strong>Agent</strong>: The learner or decision maker.</li>
<li><strong>Environment</strong>: The world with which the agent interacts.</li>
<li><strong>Action (A)</strong>: Choices made by the agent.</li>
<li><strong>State (S)</strong>: A representation of the current situation of the agent.</li>
<li><strong>Reward (R)</strong>: Feedback from the environment to evaluate the action.</li>
<li><strong>Policy (<span class="arithmatex">\(\pi\)</span>)</strong>: A mapping from states to actions.</li>
</ul>
<!-- 
- **Value Function (V)**: Estimates how good it is for the agent to be in a given state.
- **Q-Function (Q)**: Estimates the value of taking a specific action in a given state.
-->

<h3 id="learning-process">Learning Process</h3>
<p>The learning process in RL is fundamentally based on trail and error. The agent explores the environment, takes actions, observes the resulting states and rewards, and updates its policy to maximize cumulative rewards over time.</p>
<p>The goal of agent is to maximize the expected cumulative reward over time. This could mean:</p>
<ul>
<li>Maximizing immediate rewards (greedy approach)</li>
<li>Maximizing long-term rewards (planning, exploration)</li>
</ul>
<h3 id="applications">Applications</h3>
<ul>
<li>Game playing (e.g., AlphaGo, Dota 2)</li>
<li>Robotics (e.g., robotic control, manipulation)</li>
<li>Finance (e.g., trading bots, portfolio management)</li>
<li>Recommendation systems</li>
<li>Natural language processing (e.g., dialogue systems)</li>
</ul>
<hr />
<h2 id="rl-framework">RL Framework</h2>
<h3 id="agent-environment-interaction">Agent-Environment Interaction</h3>
<p>In RL, the agent continuously interact with the environment in discrete time steps. At each time step <span class="arithmatex">\(t\)</span>:</p>
<ol>
<li>The agent is in a state <span class="arithmatex">\(s_t \in S\)</span>.</li>
<li>It chooses an action <span class="arithmatex">\(a_t \in A\)</span>.</li>
<li>The environment responds by transitioning to a new state <span class="arithmatex">\(s_{t+1}\)</span> and returning a reward <span class="arithmatex">\(r_{t+1}\)</span>.</li>
</ol>
<p>This forms a sequence of interactions: <span class="arithmatex">\(s_0, a_0, r_1, s_1, a_1, r_2, s_2, \ldots\)</span></p>
<h3 id="markov-decision-process-mdp">Markov Decision Process (MDP)</h3>
<p>RL problems are commonly modeled using Markov Decision Processes (MDPs).</p>
<p>An MDP is a 5-tuple:</p>
<ul>
<li><span class="arithmatex">\(S\)</span>: Set of states</li>
<li><span class="arithmatex">\(S\)</span>: Set of actions</li>
<li><span class="arithmatex">\(P(s' |s, a)\)</span>: Transition probability - probability of next state given current state and action</li>
<li><span class="arithmatex">\(R : S \times A -&gt; \mathbb{R}\)</span>: A reward function </li>
<li><span class="arithmatex">\(\gamma\)</span>: A discount factor</li>
</ul>
<p><strong>Markov Property</strong>: The future state and reward depend only on the current state and actionnot on the full history.</p>
<h3 id="policy">Policy</h3>
<p>A policy defines the agent's behavior by mapping states to actions. It can be:</p>
<ul>
<li><strong>Deterministic</strong>: <span class="arithmatex">\(\pi(s) = a\)</span> </li>
<li><strong>Stochastic</strong>: <span class="arithmatex">\(\pi(a|s)\)</span> = <span class="arithmatex">\(P(a_t = a | s_t = s)\)</span></li>
</ul>
<h3 id="reward-signal">Reward Signal</h3>
<p>The reward signal <span class="arithmatex">\(r_t\)</span> is a scalar feedback from the environment that indicates how good or bad the action taken by the agent was.</p>
<h3 id="return-discounted-and-undiscounted">Return (Discounted and Undiscounted)</h3>
<p>The return <span class="arithmatex">\(G_t\)</span> is the cumulative reward the agent receives over time from time step t. It can be defined as:</p>
<ul>
<li><strong>Undiscounted Return</strong>: <span class="arithmatex">\(G_t = \sum_{i=0}^{\infty} r_{t+i+1}\)</span></li>
<li><strong>Discounted Return</strong>: <span class="arithmatex">\(G_t = \sum_{i=0}^{\infty} \gamma^{i} r_{t+i+1}\)</span></li>
</ul>
<p>where <span class="arithmatex">\(\gamma\)</span> is the discount factor (0  <span class="arithmatex">\(\gamma\)</span> &lt; 1). The discount factor determines the importance of future rewards. A <span class="arithmatex">\(\gamma\)</span> close to 0 makes the agent focus on immediate rewards, while a <span class="arithmatex">\(\gamma\)</span> close to 1 makes it consider long-term rewards.</p>
<h3 id="value-functions">Value Functions</h3>
<p>Value functions estimate how good it is for the agent to be in a given state or to take a specific action in that state.</p>
<p><strong>State-value function</strong>: <span class="arithmatex">\(V(s)=\mathbb{E}[G_t | s_t = s]\)</span><br />
<strong>Action-value function</strong>: <span class="arithmatex">\(Q(s, a)=\mathbb{E}[G_t | s_t = s, a_t = a]\)</span><br />
<strong>Advantage function</strong>: <span class="arithmatex">\(A(s, a) = Q(s, a) - V(s)\)</span></p>
<h3 id="bellman-equations">Bellman Equations</h3>
<p>The Bellman equations provide a recursive relationship for value functions:</p>
<p><strong>State-value function</strong>:</p>
<div class="arithmatex">\[V(s) = \mathbb{E}_{a \sim \pi} [R(s, a) + \gamma \sum_{s'} P(s' | s, a) V(s')]\]</div>
<p><strong>Action-value function</strong>:</p>
<div class="arithmatex">\[Q(s, a) = R(s, a) + \gamma \sum_{s'} P(s' | s, a) \mathbb{E}_{a' \sim \pi} [Q(s', a')]\]</div>
<p><strong>Optimal Value Functions</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(V^*(s) = \max_{a} Q^*(s, a)\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(Q^*(s, a) = R(s, a) + \gamma \max_{a'} \sum_{s'} P(s' | s, a) Q^*(s', a')\)</span>\)</span></p>
<hr />
<h2 id="exploration-and-exploitation">Exploration and Exploitation</h2>
<p>At every step, the agent faces a trade-off between exploration (trying new actions to discover their effects) and exploitation (choosing the best-known action to maximize reward). Too much exploration can lead to suboptimal performance, while too much exploitation can prevent the agent from discovering better strategies.</p>
<h3 id="greedy-strategy">Greedy Strategy</h3>
<h3 id="epsilon-greedy-strategy">Epsilon-Greedy Strategy</h3>
<h3 id="softmax-exploration">Softmax Exploration</h3>
<h3 id="upper-confidence-bound-ucb">Upper Confidence Bound (UCB)</h3>
<hr />
<h2 id="classical-rl-algorithms">Classical RL Algorithms</h2>
<hr />
<h3 id="dynamic-programming">Dynamic Programming</h3>
<hr />
<h3 id="monte-carlo-methods">Monte Carlo Methods</h3>
<hr />
<h3 id="temporal-difference-learning">Temporal Difference Learning</h3>
<hr />
<h3 id="eligibility-traces">Eligibility Traces</h3>
<hr />
<h2 id="function-approximation">Function Approximation</h2>
<h3 id="value-function-approximation">Value Function Approximation</h3>
<h3 id="policy-approximation">Policy Approximation</h3>
<h3 id="actor-critic-methods">Actor-Critic Methods</h3>
<hr />
<h2 id="deep-reinforcement-learning">Deep Reinforcement Learning</h2>
<h3 id="deep-q-networks-dqn">Deep Q-Networks (DQN)</h3>
<h3 id="advanced-policy-gradient-methods">Advanced Policy Gradient Methods</h3>
<h3 id="model-based-rl">Model-Based RL</h3>
<h2 id="the-rl-problem">The RL Problem</h2>
<p>The goal in RL is to find a policy that maximizes the cumulative reward over time. The agent observes the state, takes an action, receives a reward, and transitions to a new state. This process is often modeled as a Markov Decision Process (MDP).</p>
<h3 id="markov-decision-process-mdp_1">Markov Decision Process (MDP)</h3>
<p>An MDP is defined by:</p>
<ul>
<li>A set of states <span class="arithmatex">\(S\)</span></li>
<li>A set of actions <span class="arithmatex">\(A\)</span></li>
<li>A transition function <span class="arithmatex">\(T(s, a, s')\)</span></li>
<li>A reward function <span class="arithmatex">\(R : S \times A -&gt; \mathbb{R}\)</span></li>
<li>A discount factor <span class="arithmatex">\(\gamma\)</span> (gamma)</li>
</ul>
<h2 id="types-of-rl-algorithms">Types of RL Algorithms</h2>
<h3 id="1-value-based-methods">1. Value-Based Methods</h3>
<ul>
<li><strong>Q-Learning</strong>: Learns the value of action-state pairs.</li>
<li><strong>SARSA</strong>: Similar to Q-learning but updates using the action actually taken.</li>
</ul>
<h3 id="2-policy-based-methods">2. Policy-Based Methods</h3>
<ul>
<li><strong>REINFORCE</strong>: Directly optimizes the policy without using a value function.</li>
<li><strong>Actor-Critic</strong>: Combines value and policy-based methods.</li>
</ul>
<h3 id="3-model-based-methods">3. Model-Based Methods</h3>
<ul>
<li>The agent builds a model of the environment and plans by simulating future states.</li>
</ul>
<h2 id="exploration-vs-exploitation">Exploration vs. Exploitation</h2>
<p>A fundamental challenge in RL is balancing exploration (trying new actions) and exploitation (choosing known rewarding actions). Strategies like -greedy and Upper Confidence Bound (UCB) are commonly used.</p>
<h2 id="deep-reinforcement-learning_1">Deep Reinforcement Learning</h2>
<p>With the advent of deep learning, RL has been combined with neural networks to handle high-dimensional state spaces (e.g., images). Notable algorithms include:</p>
<ul>
<li><strong>Deep Q-Networks (DQN)</strong></li>
<li><strong>Deep Deterministic Policy Gradient (DDPG)</strong></li>
<li><strong>Proximal Policy Optimization (PPO)</strong></li>
<li><strong>Trust Region Policy Optimization (TRPO)</strong></li>
</ul>
<h2 id="applications-of-rl">Applications of RL</h2>
<ul>
<li>Game playing (e.g., AlphaGo, Atari)</li>
<li>Robotics</li>
<li>Autonomous vehicles</li>
<li>Recommendation systems</li>
<li>Finance and trading</li>
</ul>
<h2 id="challenges-in-rl">Challenges in RL</h2>
<ul>
<li>Sample inefficiency</li>
<li>Credit assignment problem</li>
<li>Exploration in large or continuous spaces</li>
<li>Stability and convergence</li>
</ul>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li>Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement Learning: An Introduction</em>.</li>
<li>OpenAI Spinning Up: https://spinningup.openai.com/</li>
<li>David Silver's RL Course: https://www.davidsilver.uk/teaching/</li>
</ul>
<hr />
<p>Reinforcement Learning is a powerful paradigm for sequential decision making, with growing impact across AI and real-world applications. As research advances, RL continues to unlock new possibilities in artificial intelligence.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy", "navigation.path", "navigation.indexes", "navigation.top"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>